{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# üéì Multi-College Engineering Admissions Chatbot\n",
        "\n",
        "## Comprehensive chatbot for Top 300+ Engineering Colleges in India\n",
        "\n",
        "### Features:\n",
        "- **15+ Top Engineering Colleges** (IITs, NITs, Private Universities)\n",
        "- **Comprehensive Data** - Admissions, Fees, Placements, Facilities\n",
        "- **Smart College Comparison** - Compare multiple colleges\n",
        "- **Advanced Search** - Find colleges by location, ranking, fees\n",
        "- **Real-time Updates** - Latest 2025-26 admission data\n",
        "\n",
        "### Supported Colleges:\n",
        "- **IITs**: Bombay, Delhi, Madras, Kanpur, Kharagpur, Roorkee\n",
        "- **NITs**: Trichy, Surathkal, Warangal\n",
        "- **Private**: BITS Pilani, VIT Vellore, SRM Chennai\n",
        "- **State**: Anna University, Jadavpur University\n",
        "- **Special**: Kalasalingam University (Detailed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_packages"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q -U langchain langchain-community faiss-cpu sentence-transformers transformers torch pandas\n",
        "print(\"‚úÖ All packages installed!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Any, Optional\n",
        "\n",
        "# LangChain imports\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.schema import Document\n",
        "\n",
        "# Transformers imports\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "\n",
        "print(\"‚úÖ All libraries imported successfully!\")"
      ],
      "metadata": {
        "id": "imports"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multi-College Data Loader\n",
        "class MultiCollegeLoader:\n",
        "    def __init__(self, base_directory: str = \"college_data\"):\n",
        "        self.base_directory = Path(base_directory)\n",
        "        self.colleges = {}\n",
        "        \n",
        "    def discover_colleges(self) -> List[str]:\n",
        "        \"\"\"Discover all college directories\"\"\"\n",
        "        if not self.base_directory.exists():\n",
        "            return []\n",
        "        \n",
        "        colleges = []\n",
        "        for item in self.base_directory.iterdir():\n",
        "            if item.is_dir() and not item.name.startswith('.'):\n",
        "                colleges.append(item.name)\n",
        "        \n",
        "        return sorted(colleges)\n",
        "    \n",
        "    def load_college_data(self, college_name: str) -> Dict[str, Any]:\n",
        "        \"\"\"Load all JSON files for a college\"\"\"\n",
        "        college_path = self.base_directory / college_name\n",
        "        \n",
        "        if not college_path.exists():\n",
        "            return {}\n",
        "        \n",
        "        college_data = {}\n",
        "        json_files = list(college_path.glob(\"*.json\"))\n",
        "        \n",
        "        for json_file in json_files:\n",
        "            file_key = json_file.stem\n",
        "            try:\n",
        "                with open(json_file, 'r', encoding='utf-8') as f:\n",
        "                    college_data[file_key] = json.load(f)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {json_file}: {e}\")\n",
        "        \n",
        "        return college_data\n",
        "    \n",
        "    def convert_to_documents(self) -> List[Document]:\n",
        "        \"\"\"Convert all college data to LangChain documents\"\"\"\n",
        "        documents = []\n",
        "        colleges = self.discover_colleges()\n",
        "        \n",
        "        print(f\"üìö Loading data for {len(colleges)} colleges...\")\n",
        "        \n",
        "        for college_name in colleges:\n",
        "            college_data = self.load_college_data(college_name)\n",
        "            \n",
        "            if not college_data:\n",
        "                continue\n",
        "            \n",
        "            # Convert each college's data to formatted text\n",
        "            college_text = self.format_college_data(college_name, college_data)\n",
        "            \n",
        "            doc = Document(\n",
        "                page_content=college_text,\n",
        "                metadata={\n",
        "                    \"college_name\": college_name,\n",
        "                    \"source\": f\"college_data/{college_name}\",\n",
        "                    \"data_files\": list(college_data.keys())\n",
        "                }\n",
        "            )\n",
        "            \n",
        "            documents.append(doc)\n",
        "            print(f\"  ‚úÖ Loaded: {college_name}\")\n",
        "        \n",
        "        return documents\n",
        "    \n",
        "    def format_college_data(self, college_name: str, college_data: Dict[str, Any]) -> str:\n",
        "        \"\"\"Format college data into readable text\"\"\"\n",
        "        \n",
        "        def format_json_section(obj, level=0):\n",
        "            lines = []\n",
        "            indent = \"  \" * level\n",
        "            \n",
        "            if isinstance(obj, dict):\n",
        "                for key, value in obj.items():\n",
        "                    formatted_key = key.replace('_', ' ').title()\n",
        "                    if isinstance(value, (dict, list)):\n",
        "                        lines.append(f\"{indent}**{formatted_key}:**\")\n",
        "                        lines.extend(format_json_section(value, level + 1))\n",
        "                    else:\n",
        "                        lines.append(f\"{indent}**{formatted_key}:** {value}\")\n",
        "            elif isinstance(obj, list):\n",
        "                for item in obj:\n",
        "                    if isinstance(item, (dict, list)):\n",
        "                        lines.extend(format_json_section(item, level))\n",
        "                    else:\n",
        "                        lines.append(f\"{indent}- {item}\")\n",
        "            return lines\n",
        "        \n",
        "        content_lines = [f\"# {college_name} - Complete Information\\n\"]\n",
        "        \n",
        "        for file_key, data in college_data.items():\n",
        "            section_title = file_key.replace('_', ' ').title()\n",
        "            content_lines.append(f\"\\n## {section_title}\\n\")\n",
        "            content_lines.extend(format_json_section(data))\n",
        "        \n",
        "        return \"\\n\".join(content_lines)\n",
        "\n",
        "# Initialize the loader\n",
        "loader = MultiCollegeLoader()\n",
        "print(\"‚úÖ Multi-College Loader initialized!\")"
      ],
      "metadata": {
        "id": "multi_college_loader"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load all college data and create documents\n",
        "print(\"üîÑ Loading all college data...\")\n",
        "\n",
        "# Convert all college data to documents\n",
        "all_documents = loader.convert_to_documents()\n",
        "\n",
        "print(f\"\\nüìä Data Summary:\")\n",
        "print(f\"Total colleges loaded: {len(all_documents)}\")\n",
        "\n",
        "# Show college list\n",
        "colleges_list = [doc.metadata['college_name'] for doc in all_documents]\n",
        "print(f\"\\nüè´ Colleges in database:\")\n",
        "for i, college in enumerate(colleges_list, 1):\n",
        "    print(f\"  {i:2d}. {college}\")\n",
        "\n",
        "print(f\"\\n‚úÖ All college data loaded successfully!\")"
      ],
      "metadata": {
        "id": "load_all_data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process documents and create vector store\n",
        "print(\"üîÑ Processing documents for enhanced search...\")\n",
        "\n",
        "# Split documents into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1200,\n",
        "    chunk_overlap=200,\n",
        "    length_function=len,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \"##\", \"**\", \"- \", \" \", \"\"]\n",
        ")\n",
        "\n",
        "docs = text_splitter.split_documents(all_documents)\n",
        "print(f\"üìù Split into {len(docs)} chunks for better processing\")\n",
        "\n",
        "# Create embeddings\n",
        "print(\"üß† Creating embeddings...\")\n",
        "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=model_name,\n",
        "    model_kwargs={'device': 'cpu'},\n",
        "    encode_kwargs={'normalize_embeddings': True}\n",
        ")\n",
        "\n",
        "# Create vector store\n",
        "print(\"üóÑÔ∏è Building comprehensive vector database...\")\n",
        "vector_store = FAISS.from_documents(docs, embedding=embeddings)\n",
        "\n",
        "print(\"‚úÖ Multi-college knowledge base created successfully!\")"
      ],
      "metadata": {
        "id": "process_docs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load language model\n",
        "print(\"ü§ñ Loading language model...\")\n",
        "\n",
        "model_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "# Create pipeline\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=512,\n",
        "    temperature=0.7,\n",
        "    do_sample=True,\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=pipe)\n",
        "\n",
        "print(\"‚úÖ Language model loaded successfully!\")"
      ],
      "metadata": {
        "id": "load_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create enhanced multi-college prompt template\n",
        "multi_college_prompt_template = \"\"\"\n",
        "You are an expert admissions counselor for engineering colleges in India. \n",
        "You have comprehensive information about top engineering colleges including IITs, NITs, and private universities.\n",
        "\n",
        "Guidelines:\n",
        "- Provide accurate, specific information based on the context\n",
        "- When comparing colleges, highlight key differences\n",
        "- Include relevant details like fees, rankings, location, and specializations\n",
        "- If asked about multiple colleges, provide comparative information\n",
        "- For admission queries, mention entrance exams and eligibility\n",
        "- Be helpful and provide actionable advice\n",
        "- If information is not available, suggest contacting the college directly\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Expert Answer:\"\"\"\n",
        "\n",
        "MULTI_COLLEGE_PROMPT = PromptTemplate(\n",
        "    template=multi_college_prompt_template, \n",
        "    input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "\n",
        "# Create QA chain\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=vector_store.as_retriever(\n",
        "        search_type=\"similarity\",\n",
        "        search_kwargs={\"k\": 6}  # Retrieve more documents for better coverage\n",
        "    ),\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": MULTI_COLLEGE_PROMPT}\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Multi-college chatbot is ready!\")"
      ],
      "metadata": {
        "id": "create_chain"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced response formatter with college identification\n",
        "def format_multi_college_response(result):\n",
        "    \"\"\"Format the chatbot response with college sources\"\"\"\n",
        "    answer = result['result'].strip()\n",
        "    sources = result.get('source_documents', [])\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üéì Multi-College Engineering Admissions Assistant\")\n",
        "    print(\"=\"*70)\n",
        "    print(answer)\n",
        "    \n",
        "    if sources:\n",
        "        # Extract unique colleges from sources\n",
        "        colleges_mentioned = set()\n",
        "        for doc in sources:\n",
        "            college_name = doc.metadata.get('college_name', 'Unknown')\n",
        "            colleges_mentioned.add(college_name)\n",
        "        \n",
        "        print(f\"\\nüìö Information sources ({len(colleges_mentioned)} colleges):\")\n",
        "        for i, college in enumerate(sorted(colleges_mentioned), 1):\n",
        "            print(f\"  {i}. {college}\")\n",
        "    \n",
        "    print(\"=\"*70)\n",
        "\n",
        "# Test the multi-college chatbot\n",
        "print(\"üéØ Testing the multi-college chatbot...\")\n",
        "\n",
        "test_questions = [\n",
        "    \"Compare IIT Bombay and IIT Delhi\",\n",
        "    \"What are the fees for BITS Pilani?\",\n",
        "    \"Which NITs are the best for computer science?\",\n",
        "    \"Tell me about admission process for IITs\"\n",
        "]\n",
        "\n",
        "for question in test_questions:\n",
        "    print(f\"\\n‚ùì Test Question: {question}\")\n",
        "    try:\n",
        "        result = qa_chain({\"query\": question})\n",
        "        format_multi_college_response(result)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error: {e}\")\n",
        "    print(\"\\n\" + \"-\"*50)"
      ],
      "metadata": {
        "id": "test_chatbot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Interactive Multi-College Chat Session\n",
        "print(\"\\nüéì Welcome to the Multi-College Engineering Admissions Chatbot!\")\n",
        "print(f\"I have information about {len(colleges_list)} top engineering colleges in India.\")\n",
        "print(\"\\nüè´ Available Colleges:\")\n",
        "for college in colleges_list:\n",
        "    print(f\"  ‚Ä¢ {college}\")\n",
        "\n",
        "print(\"\\nüí° Sample Questions:\")\n",
        "print(\"  ‚Ä¢ Compare IIT Bombay vs IIT Delhi\")\n",
        "print(\"  ‚Ä¢ What are the fees for BITS Pilani?\")\n",
        "print(\"  ‚Ä¢ Best NITs for computer science\")\n",
        "print(\"  ‚Ä¢ Admission process for private colleges\")\n",
        "print(\"  ‚Ä¢ Placement statistics comparison\")\n",
        "\n",
        "print(\"\\nType 'exit' to end the conversation.\\n\")\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        query = input(\"\\nü§î Your Question: \")\n",
        "        \n",
        "        if query.lower() in ['exit', 'quit', 'bye']:\n",
        "            print(\"\\nüëã Thank you for using the Multi-College Admissions Chatbot!\")\n",
        "            print(\"Good luck with your engineering college selection! üöÄ\")\n",
        "            break\n",
        "            \n",
        "        if query.strip() == '':\n",
        "            continue\n",
        "            \n",
        "        # Get response\n",
        "        result = qa_chain({\"query\": query})\n",
        "        format_multi_college_response(result)\n",
        "        \n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n\\nüëã Chat session ended. Thank you!\")\n",
        "        break\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Sorry, I encountered an error: {e}\")\n",
        "        print(\"Please try rephrasing your question.\")"
      ],
      "metadata": {
        "id": "interactive_chat"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
