#!/usr/bin/env python3
"""
Offline Dynamic College AI - No API Keys Required
Uses local models for translation and language detection
"""

import os
import json
import time
import pickle
import re
from pathlib import Path
from typing import Dict, List, Any
import hashlib
from datetime import datetime

# Offline language detection patterns
LANGUAGE_PATTERNS = {
    'hi': [r'[\u0900-\u097F]', r'(à¤¹à¥ˆ|à¤®à¥‡à¤‚|à¤•à¤¾|à¤•à¥€|à¤•à¥‡|à¤¸à¥‡|à¤•à¥‹|à¤”à¤°|à¤¯à¤¾|à¤•à¤¿|à¤•à¥ˆà¤¸à¥‡|à¤•à¥à¤¯à¤¾|à¤•à¤¹à¤¾à¤|à¤•à¤¬|à¤•à¥Œà¤¨)'],
    'bn': [r'[\u0980-\u09FF]', r'(à¦†à¦›à§‡|à¦à¦°|à¦à¦¬à¦‚|à¦•à¦¿|à¦•à¦¿à¦­à¦¾à¦¬à§‡|à¦•à§‹à¦¥à¦¾à¦¯à¦¼|à¦•à¦–à¦¨|à¦•à§‡|à¦•à§‡à¦¨)'],
    'te': [r'[\u0C00-\u0C7F]', r'(à°‰à°‚à°¦à°¿|à°²à±‹|à°®à°°à°¿à°¯à±|à°à°²à°¾|à°à°•à±à°•à°¡|à°à°ªà±à°ªà±à°¡à±|à°à°µà°°à±|à°à°‚à°¦à±à°•à±)'],
    'ta': [r'[\u0B80-\u0BFF]', r'(à®‰à®³à¯à®³à®¤à¯|à®‡à®²à¯|à®®à®±à¯à®±à¯à®®à¯|à®à®ªà¯à®ªà®Ÿà®¿|à®à®™à¯à®•à¯‡|à®à®ªà¯à®ªà¯‹à®¤à¯|à®¯à®¾à®°à¯|à®à®©à¯)'],
    'mr': [r'[\u0900-\u097F]', r'(à¤†à¤¹à¥‡|à¤®à¤§à¥à¤¯à¥‡|à¤†à¤£à¤¿|à¤•à¤¸à¥‡|à¤•à¥à¤ à¥‡|à¤•à¥‡à¤µà¥à¤¹à¤¾|à¤•à¥‹à¤£|à¤•à¤¾)'],
    'gu': [r'[\u0A80-\u0AFF]', r'(àª›à«‡|àª®àª¾àª‚|àª…àª¨à«‡|àª•à«‡àªµà«€|àª•à«àª¯àª¾àª‚|àª•à«àª¯àª¾àª°à«‡|àª•à«‹àª£|àª¶àª¾)'],
    'kn': [r'[\u0C80-\u0CFF]', r'(à²‡à²¦à³†|à²¨à²²à³à²²à²¿|à²®à²¤à³à²¤à³|à²¹à³‡à²—à³†|à²à²²à³à²²à²¿|à²¯à²¾à²µà²¾à²—|à²¯à²¾à²°à³|à²à²•à³†)'],
    'ml': [r'[\u0D00-\u0D7F]', r'(à´‰à´£àµà´Ÿàµ|àµ½|à´’à´ªàµà´ªà´‚|à´à´™àµà´™à´¨àµ†|à´à´µà´¿à´Ÿàµ†|à´à´ªàµà´ªàµ‹àµ¾|à´†à´°àµ|à´à´¨àµà´¤àµà´•àµŠà´£àµà´Ÿàµ)'],
    'pa': [r'[\u0A00-\u0A7F]', r'(à¨¹à©ˆ|à¨µà¨¿à©±à¨š|à¨…à¨¤à©‡|à¨•à¨¿à¨µà©‡à¨‚|à¨•à¨¿à©±à¨¥à©‡|à¨•à¨¦à©‹à¨‚|à¨•à©Œà¨£|à¨•à¨¿à¨‰à¨‚)'],
    'or': [r'[\u0B00-\u0B7F]', r'(à¬…à¬›à¬¿|à¬°à­‡|à¬à¬¬à¬‚|à¬•à¬¿à¬ªà¬°à¬¿|à¬•à­‡à¬‰à¬à¬ à¬¿|à¬•à­‡à¬¬à­‡|à¬•à¬¿à¬|à¬•à¬¾à¬¹à¬¿à¬à¬•à¬¿)'],
    'as': [r'[\u0980-\u09FF]', r'(à¦†à¦›à§‡|à¦¤|à¦†à§°à§|à¦•à§‡à¦¨à§‡à¦•à§ˆ|à¦•\'à¦¤|à¦•à§‡à¦¤à¦¿à¦¯à¦¼à¦¾|à¦•à§‹à¦¨|à¦•à¦¿à¦¯à¦¼)'],
    'ur': [r'[\u0600-\u06FF]', r'(ÛÛ’|Ù…ÛŒÚº|Ø§ÙˆØ±|Ú©ÛŒØ³Û’|Ú©ÛØ§Úº|Ú©Ø¨|Ú©ÙˆÙ†|Ú©ÛŒÙˆÚº)']
}

# Simple translation dictionary for common words
TRANSLATION_DICT = {
    'hi': {
        'fee': 'à¤«à¥€à¤¸', 'fees': 'à¤«à¥€à¤¸', 'cost': 'à¤²à¤¾à¤—à¤¤', 'price': 'à¤•à¥€à¤®à¤¤',
        'admission': 'à¤ªà¥à¤°à¤µà¥‡à¤¶', 'college': 'à¤•à¥‰à¤²à¥‡à¤œ', 'university': 'à¤µà¤¿à¤¶à¥à¤µà¤µà¤¿à¤¦à¥à¤¯à¤¾à¤²à¤¯',
        'placement': 'à¤ªà¥à¤²à¥‡à¤¸à¤®à¥‡à¤‚à¤Ÿ', 'job': 'à¤¨à¥Œà¤•à¤°à¥€', 'salary': 'à¤µà¥‡à¤¤à¤¨',
        'course': 'à¤•à¥‹à¤°à¥à¤¸', 'engineering': 'à¤‡à¤‚à¤œà¥€à¤¨à¤¿à¤¯à¤°à¤¿à¤‚à¤—', 'computer': 'à¤•à¤‚à¤ªà¥à¤¯à¥‚à¤Ÿà¤°',
        'what': 'à¤•à¥à¤¯à¤¾', 'how': 'à¤•à¥ˆà¤¸à¥‡', 'where': 'à¤•à¤¹à¤¾à¤', 'when': 'à¤•à¤¬'
    },
    'bn': {
        'fee': 'à¦«à¦¿', 'fees': 'à¦«à¦¿', 'cost': 'à¦–à¦°à¦š', 'price': 'à¦¦à¦¾à¦®',
        'admission': 'à¦­à¦°à§à¦¤à¦¿', 'college': 'à¦•à¦²à§‡à¦œ', 'university': 'à¦¬à¦¿à¦¶à§à¦¬à¦¬à¦¿à¦¦à§à¦¯à¦¾à¦²à¦¯à¦¼',
        'placement': 'à¦šà¦¾à¦•à¦°à¦¿', 'job': 'à¦•à¦¾à¦œ', 'salary': 'à¦¬à§‡à¦¤à¦¨',
        'course': 'à¦•à§‹à¦°à§à¦¸', 'engineering': 'à¦ªà§à¦°à¦•à§Œà¦¶à¦²', 'computer': 'à¦•à¦®à§à¦ªà¦¿à¦‰à¦Ÿà¦¾à¦°',
        'what': 'à¦•à¦¿', 'how': 'à¦•à¦¿à¦­à¦¾à¦¬à§‡', 'where': 'à¦•à§‹à¦¥à¦¾à¦¯à¦¼', 'when': 'à¦•à¦–à¦¨'
    },
    'te': {
        'fee': 'à°«à±€à°œà±', 'fees': 'à°«à±€à°œà±à°²à±', 'cost': 'à°–à°°à±à°šà±', 'price': 'à°§à°°',
        'admission': 'à°ªà±à°°à°µà±‡à°¶à°‚', 'college': 'à°•à°¾à°²à±‡à°œà±€', 'university': 'à°µà°¿à°¶à±à°µà°µà°¿à°¦à±à°¯à°¾à°²à°¯à°‚',
        'placement': 'à°ªà±à°²à±‡à°¸à±â€Œà°®à±†à°‚à°Ÿà±', 'job': 'à°‰à°¦à±à°¯à±‹à°—à°‚', 'salary': 'à°œà±€à°¤à°‚',
        'course': 'à°•à±‹à°°à±à°¸à±', 'engineering': 'à°‡à°‚à°œà°¨à±€à°°à°¿à°‚à°—à±', 'computer': 'à°•à°‚à°ªà±à°¯à±‚à°Ÿà°°à±',
        'what': 'à°à°®à°¿à°Ÿà°¿', 'how': 'à°à°²à°¾', 'where': 'à°à°•à±à°•à°¡', 'when': 'à°à°ªà±à°ªà±à°¡à±'
    }
}

class OfflineTranslator:
    """Offline translator using local patterns and dictionaries"""
    
    def __init__(self):
        self.supported_languages = list(LANGUAGE_PATTERNS.keys()) + ['en']
        print("ğŸ”¤ Offline translator initialized")
        print(f"ğŸŒ Supported languages: {len(self.supported_languages)}")
    
    def detect_language(self, text: str) -> str:
        """Detect language using character patterns"""
        if not text.strip():
            return 'en'
        
        text_lower = text.lower()
        
        # Check for English first
        if re.search(r'^[a-zA-Z0-9\s\.,\?!]+$', text):
            return 'en'
        
        # Check each language pattern
        for lang_code, patterns in LANGUAGE_PATTERNS.items():
            for pattern in patterns:
                if re.search(pattern, text):
                    return lang_code
        
        return 'en'  # Default to English
    
    def translate_text(self, text: str, target_lang: str, source_lang: str = 'auto') -> str:
        """Simple offline translation using word mapping"""
        if source_lang == 'auto':
            source_lang = self.detect_language(text)
        
        if source_lang == target_lang:
            return text
        
        # English to other languages
        if source_lang == 'en' and target_lang in TRANSLATION_DICT:
            return self._translate_en_to_lang(text, target_lang)
        
        # Other languages to English
        if target_lang == 'en' and source_lang in TRANSLATION_DICT:
            return self._translate_lang_to_en(text, source_lang)
        
        # If no translation available, return original
        return text
    
    def _translate_en_to_lang(self, text: str, target_lang: str) -> str:
        """Translate English to target language"""
        if target_lang not in TRANSLATION_DICT:
            return text
        
        words = text.lower().split()
        translated_words = []
        
        for word in words:
            # Remove punctuation for lookup
            clean_word = re.sub(r'[^\w]', '', word)
            if clean_word in TRANSLATION_DICT[target_lang]:
                translated_words.append(TRANSLATION_DICT[target_lang][clean_word])
            else:
                translated_words.append(word)
        
        return ' '.join(translated_words)
    
    def _translate_lang_to_en(self, text: str, source_lang: str) -> str:
        """Translate from source language to English"""
        if source_lang not in TRANSLATION_DICT:
            return text
        
        # Reverse lookup in translation dictionary
        reverse_dict = {v: k for k, v in TRANSLATION_DICT[source_lang].items()}
        
        words = text.split()
        translated_words = []
        
        for word in words:
            clean_word = re.sub(r'[^\w]', '', word)
            if clean_word in reverse_dict:
                translated_words.append(reverse_dict[clean_word])
            else:
                translated_words.append(word)
        
        return ' '.join(translated_words)

class OfflineDynamicCollegeAI:
    """Offline Dynamic College AI - No API Keys Required"""
    
    def __init__(self, base_model_path: str = "college_ai_rtx2050_trained.pkl"):
        self.base_model_path = base_model_path
        self.data_path = Path("college_data")
        self.cache_path = Path("dynamic_cache")
        self.cache_path.mkdir(exist_ok=True)
        
        # Initialize offline translator
        self.translator = OfflineTranslator()
        
        # Load base trained model
        self.base_agent = None
        self.load_base_model()
        
        # Dynamic data tracking
        self.data_hash_file = self.cache_path / "data_hash.json"
        self.new_data_cache = self.cache_path / "new_data.json"
        self.last_scan_time = 0
        
        # Initialize data monitoring
        self.current_data_hash = self.calculate_data_hash()
        self.new_colleges = {}
        self.updated_colleges = {}
        
        print("ğŸ”„ Offline Dynamic College AI initialized")
        print(f"ğŸ“Š Base model: {len(self.base_agent.colleges_data) if self.base_agent else 0} colleges")
        print("ğŸ”’ No API keys required - fully offline!")
    
    def load_base_model(self):
        """Load the base trained model"""
        try:
            if Path(self.base_model_path).exists():
                with open(self.base_model_path, 'rb') as f:
                    model_data = pickle.load(f)
                
                # Create a simple agent-like object
                class SimpleAgent:
                    def __init__(self, data):
                        self.colleges_data = data.get('colleges_data', {})
                        self.qa_pairs = data.get('qa_pairs', [])
                        self.embeddings = data.get('embeddings')
                
                self.base_agent = SimpleAgent(model_data)
                print(f"âœ… Base model loaded: {self.base_model_path}")
                return True
            else:
                print(f"âŒ Base model not found: {self.base_model_path}")
                return False
                
        except Exception as e:
            print(f"âŒ Error loading base model: {e}")
            return False
    
    def calculate_data_hash(self):
        """Calculate hash of all college data for change detection"""
        if not self.data_path.exists():
            return ""
        
        all_files_content = []
        
        for college_dir in sorted(self.data_path.iterdir()):
            if college_dir.is_dir():
                for json_file in sorted(college_dir.glob("*.json")):
                    try:
                        with open(json_file, 'r', encoding='utf-8') as f:
                            content = f.read()
                            all_files_content.append(f"{json_file.name}:{content}")
                    except Exception:
                        continue
        
        combined_content = "".join(all_files_content)
        return hashlib.md5(combined_content.encode()).hexdigest()
    
    def detect_data_changes(self):
        """Detect if college data has been updated"""
        new_hash = self.calculate_data_hash()
        
        # Load previous hash
        previous_hash = ""
        if self.data_hash_file.exists():
            try:
                with open(self.data_hash_file, 'r') as f:
                    hash_data = json.load(f)
                    previous_hash = hash_data.get('hash', '')
            except Exception:
                pass
        
        # Check for changes
        if new_hash != previous_hash:
            print(f"ğŸ”„ Data changes detected!")
            self.scan_for_new_data()
            
            # Update hash file
            with open(self.data_hash_file, 'w') as f:
                json.dump({
                    'hash': new_hash,
                    'last_update': datetime.now().isoformat(),
                    'scan_time': time.time()
                }, f, indent=2)
            
            return True
        
        return False
    
    def scan_for_new_data(self):
        """Scan for new or updated college data"""
        print("ğŸ” Scanning for new college data...")
        
        if not self.base_agent:
            print("âŒ Base model not available")
            return
        
        existing_colleges = set(self.base_agent.colleges_data.keys())
        current_colleges = set()
        
        new_data = {
            'new_colleges': {},
            'updated_colleges': {},
            'scan_time': time.time()
        }
        
        # Scan all college directories
        for college_dir in self.data_path.iterdir():
            if college_dir.is_dir():
                college_name = college_dir.name
                current_colleges.add(college_name)
                
                # Load college data
                college_data = self.load_college_data(college_dir)
                
                if college_name not in existing_colleges:
                    # New college found
                    print(f"ğŸ†• New college: {college_name}")
                    new_data['new_colleges'][college_name] = college_data
                else:
                    # Check if existing college data changed
                    if self.has_college_data_changed(college_name, college_data):
                        print(f"ğŸ”„ Updated college: {college_name}")
                        new_data['updated_colleges'][college_name] = college_data
        
        # Save new data cache
        with open(self.new_data_cache, 'w', encoding='utf-8') as f:
            json.dump(new_data, f, indent=2, ensure_ascii=False)
        
        self.new_colleges = new_data['new_colleges']
        self.updated_colleges = new_data['updated_colleges']
        
        total_changes = len(self.new_colleges) + len(self.updated_colleges)
        print(f"âœ… Scan complete: {len(self.new_colleges)} new, {len(self.updated_colleges)} updated")
        
        return total_changes > 0
    
    def load_college_data(self, college_dir: Path):
        """Load all data for a college"""
        college_data = {}
        
        for json_file in college_dir.glob("*.json"):
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    file_key = json_file.stem
                    college_data[file_key] = data
            except Exception as e:
                print(f"âš ï¸  Error loading {json_file}: {e}")
        
        return college_data
    
    def has_college_data_changed(self, college_name: str, new_data: Dict):
        """Check if college data has changed"""
        if college_name not in self.base_agent.colleges_data:
            return True
        
        old_data = self.base_agent.colleges_data[college_name]
        
        old_str = json.dumps(old_data, sort_keys=True)
        new_str = json.dumps(new_data, sort_keys=True)
        
        return old_str != new_str
    
    def query_with_offline_translation(self, question: str, top_k: int = 5, target_language: str = None):
        """Query with offline translation and dynamic data"""
        # Detect language if not specified
        if target_language is None:
            target_language = self.translator.detect_language(question)
        
        print(f"ğŸ” Detected language: {target_language}")
        
        # Translate question to English for searching
        english_question = question
        if target_language != 'en':
            english_question = self.translator.translate_text(question, 'en', target_language)
            print(f"ğŸ”„ Translated query: {english_question}")
        
        # Check for data changes
        current_time = time.time()
        if current_time - self.last_scan_time > 60:  # Check every minute
            self.detect_data_changes()
            self.last_scan_time = current_time
        
        # Search in base model (simplified)
        base_results = self.search_base_model(english_question)
        
        # Search in new/updated data
        dynamic_results = self.search_dynamic_data(english_question)
        
        # Combine results
        all_results = base_results + dynamic_results
        
        # Sort by relevance
        all_results.sort(key=lambda x: x.get('confidence', 0), reverse=True)
        
        # Translate results back if needed
        if target_language != 'en':
            for result in all_results:
                result['answer'] = self.translator.translate_text(result['answer'], target_language, 'en')
                result['translated'] = True
        
        return all_results[:top_k]
    
    def search_base_model(self, question: str):
        """Simple search in base model data"""
        results = []
        question_lower = question.lower()
        
        # Simple keyword matching in Q&A pairs
        for qa in self.base_agent.qa_pairs[:100]:  # Limit for demo
            qa_text = f"{qa.get('question', '')} {qa.get('answer', '')}".lower()
            
            # Calculate simple relevance score
            score = 0
            question_words = question_lower.split()
            for word in question_words:
                if len(word) > 2 and word in qa_text:
                    score += 1
            
            if score > 0:
                results.append({
                    'college': qa.get('college', 'Unknown'),
                    'category': qa.get('category', 'general'),
                    'question': qa.get('question', ''),
                    'answer': qa.get('answer', ''),
                    'confidence': min(score * 20, 95),
                    'source': 'base'
                })
        
        return sorted(results, key=lambda x: x['confidence'], reverse=True)[:5]
    
    def search_dynamic_data(self, question: str):
        """Search in new/updated college data"""
        results = []
        question_lower = question.lower()
        
        # Search new colleges
        for college_name, college_data in self.new_colleges.items():
            score = self.calculate_relevance_score(question_lower, college_data)
            if score > 0.3:
                answer = self.generate_answer_from_data(question, college_data)
                
                results.append({
                    'college': f"ğŸ†• {college_name}",
                    'category': 'general',
                    'question': question,
                    'answer': answer,
                    'confidence': min(score * 100, 95),
                    'source': 'dynamic'
                })
        
        # Search updated colleges
        for college_name, college_data in self.updated_colleges.items():
            score = self.calculate_relevance_score(question_lower, college_data)
            if score > 0.3:
                answer = self.generate_answer_from_data(question, college_data)
                
                results.append({
                    'college': f"ğŸ”„ {college_name}",
                    'category': 'general',
                    'question': question,
                    'answer': answer,
                    'confidence': min(score * 100, 95),
                    'source': 'dynamic'
                })
        
        return results
    
    def calculate_relevance_score(self, question: str, college_data: Dict):
        """Calculate relevance score for college data"""
        score = 0.0
        question_words = question.split()
        
        searchable_text = json.dumps(college_data, ensure_ascii=False).lower()
        
        for word in question_words:
            if len(word) > 2 and word in searchable_text:
                score += 0.1
        
        # Boost for specific keywords
        if 'fee' in question and ('fee' in searchable_text or 'cost' in searchable_text):
            score += 0.3
        if 'placement' in question and 'placement' in searchable_text:
            score += 0.3
        if 'admission' in question and 'admission' in searchable_text:
            score += 0.3
        
        return min(score, 1.0)
    
    def generate_answer_from_data(self, question: str, college_data: Dict):
        """Generate answer from college data"""
        if 'fee' in question.lower():
            if 'basic_info' in college_data and 'fees' in str(college_data['basic_info']).lower():
                return f"Fee information: {str(college_data.get('basic_info', {}))[:200]}..."
        
        if 'placement' in question.lower():
            if 'placements' in college_data:
                return f"Placement details: {str(college_data.get('placements', {}))[:200]}..."
        
        if 'admission' in question.lower():
            if 'admissions' in college_data:
                return f"Admission information: {str(college_data.get('admissions', {}))[:200]}..."
        
        return f"Information available: {str(college_data)[:200]}..."

def main():
    """Demo of offline dynamic system"""
    print("ğŸš€ Offline Dynamic College AI - No API Keys!")
    print("=" * 60)
    
    ai = OfflineDynamicCollegeAI()
    
    if not ai.base_agent:
        print("âŒ Base model not available. Please train first:")
        print("   python train_rtx2050_gpu.py")
        return
    
    print(f"\nğŸ® Interactive Mode - Ask questions in any language!")
    print("ğŸ”’ Fully offline - no internet or API keys required")
    print("Type 'quit' to exit")
    
    while True:
        try:
            query = input("\nâ“ Your question: ").strip()
            
            if query.lower() in ['quit', 'exit']:
                break
            
            if not query:
                continue
            
            print("ğŸ” Processing offline...")
            results = ai.query_with_offline_translation(query, top_k=3)
            
            if results:
                for i, result in enumerate(results, 1):
                    source_icon = "ğŸ†•" if result.get('source') == 'dynamic' else "ğŸ“š"
                    print(f"\n{i}. {source_icon} {result['college']} ({result['confidence']:.1f}%)")
                    print(f"   ğŸ’¡ {result['answer'][:150]}...")
                    if result.get('translated'):
                        print(f"   ğŸ”„ Answer translated offline")
            else:
                print("âŒ No results found")
                
        except KeyboardInterrupt:
            break
        except Exception as e:
            print(f"âŒ Error: {e}")
    
    print("ğŸ‘‹ Goodbye!")

if __name__ == "__main__":
    main()
